{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Understanding and Defining Data Quality Metrics\n",
    "**Description**: Learn how to define basic data quality metrics such as completeness, validity, and uniqueness for a simple dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Dataset: Use a CSV with columns like Name , Email , Age .\n",
    "2. Metric Definitions:\n",
    "    - Completeness: Percentage of non-null values.\n",
    "    - Validity: % of email fields containing @ .\n",
    "    - Uniqueness: Count distinct entries in the Email column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'students.csv' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataset with Name, Email, and Age\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Email': ['alice@example.com', 'bob@example', 'charlie@example.com', 'david@example.com', ''],\n",
    "    'Age': [30, 25, 35, 40, 50]\n",
    "}\n",
    "\n",
    "# Convert the dataset into a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('students.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'students.csv' has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Metrics:\n",
      "Completeness: Name     100.0\n",
      "Email     80.0\n",
      "Age      100.0\n",
      "dtype: float64\n",
      "Validity: 80.0%\n",
      "Uniqueness: 4 unique email addresses\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset from CSV\n",
    "df = pd.read_csv('students.csv')\n",
    "\n",
    "# 1. Completeness: Percentage of non-null values\n",
    "def calculate_completeness(df):\n",
    "    completeness = (df.notnull().mean()) * 100\n",
    "    return completeness\n",
    "\n",
    "# 2. Validity: % of email fields containing '@'\n",
    "def calculate_validity(df):\n",
    "    valid_email = df['Email'].str.contains('@', na=False).mean() * 100\n",
    "    return valid_email\n",
    "\n",
    "# 3. Uniqueness: Count distinct entries in the Email column\n",
    "def calculate_uniqueness(df):\n",
    "    unique_emails = df['Email'].nunique()\n",
    "    return unique_emails\n",
    "\n",
    "# Calculate metrics\n",
    "completeness = calculate_completeness(df)\n",
    "validity = calculate_validity(df)\n",
    "uniqueness = calculate_uniqueness(df)\n",
    "\n",
    "# Display results\n",
    "print(\"Data Quality Metrics:\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"Validity: {validity}%\")\n",
    "print(f\"Uniqueness: {uniqueness} unique email addresses\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Calculating Data Quality Score\n",
    "**Description**: Aggregate multiple metrics to calculate an overall data quality score.\n",
    "\n",
    "**Steps**:\n",
    "1. Formula: Simple average of all metrics defined in Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Data Quality Score: 84.44\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('students.csv')\n",
    "\n",
    "# Metric 1: Completeness (Percentage of non-null values)\n",
    "def completeness(df):\n",
    "    total_values = df.size\n",
    "    non_null_values = df.notnull().sum().sum()\n",
    "    return (non_null_values / total_values) * 100\n",
    "\n",
    "# Metric 2: Validity (Percentage of valid emails containing '@')\n",
    "def validity(df):\n",
    "    valid_emails = df['Email'].apply(lambda x: '@' in str(x)).sum()\n",
    "    return (valid_emails / len(df)) * 100\n",
    "\n",
    "# Metric 3: Uniqueness (Percentage of unique emails)\n",
    "def uniqueness(df):\n",
    "    unique_emails = df['Email'].nunique()\n",
    "    return (unique_emails / len(df)) * 100\n",
    "\n",
    "# Calculate the overall Data Quality Score (Simple Average of the metrics)\n",
    "def calculate_data_quality_score(df):\n",
    "    completeness_score = completeness(df)\n",
    "    validity_score = validity(df)\n",
    "    uniqueness_score = uniqueness(df)\n",
    "    \n",
    "    # Simple average of all metrics\n",
    "    overall_dqi = (completeness_score + validity_score + uniqueness_score) / 3\n",
    "    return overall_dqi\n",
    "\n",
    "# Calculate and print the Data Quality Score\n",
    "data_quality_score = calculate_data_quality_score(df)\n",
    "print(f\"Overall Data Quality Score: {data_quality_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Creating Expectations for a CSV\n",
    "**Description**: Develop basic data quality expectations using Great Expectations.\n",
    "\n",
    "**Steps**:\n",
    "1. Expectation Suite\n",
    "2. Define Expectations for Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'great_expectations.dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mge\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExpectationSuite\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PandasDataset\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataContext\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the dataset using pandas\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'great_expectations.dataset'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "from great_expectations.core import ExpectationSuite\n",
    "from great_expectations.dataset import PandasDataset\n",
    "from great_expectations.data_context import DataContext\n",
    "\n",
    "# Load the dataset using pandas\n",
    "df = pd.read_csv('students.csv')\n",
    "\n",
    "# Create a DataContext\n",
    "context = DataContext()\n",
    "\n",
    "# Convert pandas DataFrame to Great Expectations PandasDataset\n",
    "df_ge = ge.dataset.PandasDataset(df)\n",
    "\n",
    "# Create an expectation suite\n",
    "suite = ExpectationSuite(\"students_suite\")\n",
    "\n",
    "# Add expectations to check for completeness (non-null values) and valid emails\n",
    "df_ge.expect_column_values_to_not_be_null(\"Email\")\n",
    "df_ge.expect_column_values_to_not_be_null(\"Age\")\n",
    "df_ge.expect_column_value_lengths_to_be_between(\"Email\", min_value=5, max_value=100)\n",
    "\n",
    "# Add an expectation for valid emails (should contain '@')\n",
    "df_ge.expect_column_values_to_match_like('Email', r'.+@.+\\..+')\n",
    "\n",
    "# Validate the dataset against the expectations\n",
    "results = df_ge.validate(expectation_suite=suite)\n",
    "\n",
    "# Print the results\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Running and Validating Expectations\n",
    "**Description**: Run the created expectations and generate an output report.\n",
    "\n",
    "**Steps**:\n",
    "1. Validate\n",
    "2. Generate HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DataContext' from 'great_expectations.data_context' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/data_context/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mge\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExpectationSuite\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataContext\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load the dataset using pandas\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DataContext' from 'great_expectations.data_context' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/data_context/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "from great_expectations.core import ExpectationSuite\n",
    "from great_expectations.data_context import DataContext\n",
    "import os\n",
    "\n",
    "# Load the dataset using pandas\n",
    "df = pd.read_csv('students.csv')\n",
    "\n",
    "# Create a DataContext\n",
    "context = DataContext()\n",
    "\n",
    "# Convert pandas DataFrame to Great Expectations PandasDataset\n",
    "df_ge = ge.dataset.PandasDataset(df)\n",
    "\n",
    "# Create an expectation suite\n",
    "suite = ExpectationSuite(\"students_suite\")\n",
    "\n",
    "# Add expectations to check for completeness (non-null values) and valid emails\n",
    "df_ge.expect_column_values_to_not_be_null(\"Email\")\n",
    "df_ge.expect_column_values_to_not_be_null(\"Age\")\n",
    "df_ge.expect_column_value_lengths_to_be_between(\"Email\", min_value=5, max_value=100)\n",
    "\n",
    "# Add an expectation for valid emails (should contain '@')\n",
    "df_ge.expect_column_values_to_match_like('Email', r'.+@.+\\..+')\n",
    "\n",
    "# Validate the dataset against the expectations\n",
    "results = df_ge.validate(expectation_suite=suite)\n",
    "\n",
    "# Print the results\n",
    "print(results)\n",
    "\n",
    "# Generate the HTML report\n",
    "context.build_data_docs()\n",
    "\n",
    "# Assuming the data docs folder is generated in your context directory\n",
    "# We can access the report from the data_docs folder\n",
    "report_path = os.path.join(context.root_directory, \"uncommitted/data_docs/local_site/index.html\")\n",
    "\n",
    "print(f\"HTML report generated at: {report_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Automating Data Quality Score Calculation\n",
    "**Description**: Automate the data quality score via a script that integrates with Great\n",
    "Expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DataContext' from 'great_expectations.data_context' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/data_context/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mge\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExpectationSuite\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataContext\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the dataset using pandas\u001b[39;00m\n\u001b[1;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudents.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DataContext' from 'great_expectations.data_context' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/data_context/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "from great_expectations.data_context import DataContext\n",
    "\n",
    "# Load the dataset using pandas\n",
    "df = pd.read_csv('students.csv')\n",
    "\n",
    "# Initialize the Great Expectations DataContext\n",
    "context = DataContext()\n",
    "\n",
    "# Step 1: Define Cleaning Logic (example)\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Cleaning logic to fill missing values in Age with the mean.\n",
    "    \"\"\"\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    # Additional cleaning logic as per requirement\n",
    "    return df\n",
    "\n",
    "# Step 2: Create and Load Expectation Suite\n",
    "# Create an expectation suite for data quality expectations (can be done using the CLI, assuming suite exists)\n",
    "suite_name = \"students_suite\"\n",
    "context.create_expectation_suite(suite_name, overwrite_existing=True)\n",
    "\n",
    "# Define expectations for completeness and email validity\n",
    "batch = ge.dataset.PandasDataset(df)\n",
    "\n",
    "# Add expectations for each column\n",
    "batch.expect_column_values_to_be_in_set('Age', range(0, 120))  # Valid age range 0-120\n",
    "batch.expect_column_values_to_be_in_set('Grade', range(0, 101))  # Valid grade range 0-100\n",
    "batch.expect_column_values_to_match_like_pattern('Email', r'.+@.+\\..+')  # Valid email format\n",
    "\n",
    "# Step 3: Calculate Data Quality Score\n",
    "def calculate_dqi(df):\n",
    "    completeness = df.notnull().mean().mean() * 100  # Completeness as percentage of non-null values\n",
    "    valid_email = df['Email'].str.contains(r'.+@.+\\..+').mean() * 100  # Valid email check\n",
    "    uniqueness = df['Email'].nunique() / len(df) * 100  # Uniqueness as percentage of unique email entries\n",
    "    \n",
    "    # Simple average of all metrics for DQI\n",
    "    dqi = (completeness + valid_email + uniqueness) / 3\n",
    "    return dqi\n",
    "\n",
    "# Step 4: Trigger Data Cleaning Based on DQI Threshold\n",
    "def check_and_clean(df, threshold=85):\n",
    "    dqi = calculate_dqi(df)\n",
    "    print(f\"Current Data Quality Index (DQI): {dqi}\")\n",
    "    \n",
    "    if dqi < threshold:\n",
    "        print(f\"Data quality is below the threshold of {threshold}. Triggering cleaning process.\")\n",
    "        cleaned_df = clean_data(df)\n",
    "        cleaned_dqi = calculate_dqi(cleaned_df)\n",
    "        print(f\"New Data Quality Index (DQI) after cleaning: {cleaned_dqi}\")\n",
    "        return cleaned_df\n",
    "    else:\n",
    "        print(f\"Data quality is sufficient. No cleaning required.\")\n",
    "        return df\n",
    "\n",
    "# Step 5: Run the Cleaning Logic\n",
    "cleaned_df = check_and_clean(df)\n",
    "\n",
    "# Optionally, you can save the cleaned dataframe to a new CSV\n",
    "cleaned_df.to_csv('students_cleaned.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Leveraging Data Quality Metrics for Automated Data Cleaning\n",
    "**Description**: Implement a system where if data quality metrics fall below a threshold,\n",
    "automated data cleaning scripts are triggered.\n",
    "\n",
    "**Steps**:\n",
    "1. Define Cleaning Logic\n",
    "2. Integrate with Great Expectations:\n",
    "    - Use an action within the Great Expectations action list that only triggers if quality score is below a threshold, automating the cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define a function for removing rows with missing values\n",
    "def clean_missing_values(df):\n",
    "    print(\"Cleaning missing values...\")\n",
    "    return df.dropna()\n",
    "\n",
    "# Define a function to fix invalid email formats\n",
    "def clean_invalid_emails(df):\n",
    "    print(\"Cleaning invalid emails...\")\n",
    "    df['Email'] = df['Email'].apply(lambda x: x if '@' in str(x) else 'invalid_email@example.com')\n",
    "    return df\n",
    "\n",
    "# Define a function for removing outliers in the 'Age' column (e.g., age > 120 is considered an outlier)\n",
    "def clean_outliers(df):\n",
    "    print(\"Cleaning outliers in Age...\")\n",
    "    return df[df['Age'] <= 120]\n",
    "\n",
    "# Define the main cleaning function that integrates all the cleaning logic\n",
    "def clean_data(df):\n",
    "    df = clean_missing_values(df)\n",
    "    df = clean_invalid_emails(df)\n",
    "    df = clean_outliers(df)\n",
    "    return df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
