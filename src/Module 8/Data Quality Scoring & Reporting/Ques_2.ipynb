{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Data Quality Dashboard\n",
    "\n",
    "**Description**: Create a simple dashboard that displays data quality metrics using a library like `dash` or `streamlit`.\n",
    "\n",
    "**Steps:**\n",
    "1. Install Streamlit: pip install streamlit\n",
    "2. Create a Python script dashboard.py.\n",
    "3. Run the dashboard: streamlit run dashboard.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 18:46:41.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-11 18:46:41.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-11 18:46:41.062 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-11 18:46:41.063 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-11 18:46:41.064 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-11 18:46:41.064 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-11 18:46:41.065 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-11 18:46:41.065 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-11 18:46:41.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-11 18:46:41.068 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# dashboard.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set Streamlit page configuration\n",
    "st.set_page_config(page_title=\"Data Quality Dashboard\", layout=\"centered\")\n",
    "\n",
    "# Dashboard Title\n",
    "st.title(\"üìä Data Quality Dashboard\")\n",
    "\n",
    "# Upload CSV\n",
    "uploaded_file = st.file_uploader(\"Upload your CSV file\", type=[\"csv\"])\n",
    "\n",
    "# When a file is uploaded, process and display data\n",
    "if uploaded_file is not None:\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        st.success(\"‚úÖ File successfully loaded!\")\n",
    "\n",
    "        # Display preview of the dataset\n",
    "        st.subheader(\"üîç Dataset Preview\")\n",
    "        st.dataframe(df.head())\n",
    "\n",
    "        # Calculate Data Quality Index (DQI)\n",
    "        total_cells = df.size\n",
    "        total_missing = df.isnull().sum().sum()\n",
    "        dqi = round((1 - total_missing / total_cells) * 100, 2)\n",
    "\n",
    "        # Show Data Quality Metrics\n",
    "        st.subheader(\"üìà Data Quality Metrics\")\n",
    "        st.metric(label=\"Total Rows\", value=df.shape[0])\n",
    "        st.metric(label=\"Total Columns\", value=df.shape[1])\n",
    "        st.metric(label=\"Total Missing Values\", value=total_missing)\n",
    "        st.metric(label=\"Data Quality Index (DQI)\", value=f\"{dqi} %\")\n",
    "\n",
    "        # Display a bar plot for DQI and Errors\n",
    "        st.subheader(\"üìä DQI vs Errors (%)\")\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.bar([\"DQI\", \"Errors\"], [dqi, 100 - dqi], color=[\"green\", \"red\"])\n",
    "        ax.set_ylabel(\"Percentage\")\n",
    "        ax.set_ylim([0, 100])\n",
    "        for i, val in enumerate([dqi, 100 - dqi]):\n",
    "            ax.text(i, val + 2, f\"{val:.2f}%\", ha='center')\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        # Display missing values per column\n",
    "        st.subheader(\"üßÆ Missing Values per Column\")\n",
    "        missing_per_column = df.isnull().sum()\n",
    "        st.bar_chart(missing_per_column)\n",
    "\n",
    "    except pd.errors.ParserError:\n",
    "        st.error(\"‚ùå The file appears to be malformed. Please check the CSV format.\")\n",
    "    except UnicodeDecodeError:\n",
    "        st.error(\"‚ùå The file contains unsupported characters. Try another encoding.\")\n",
    "    except ValueError:\n",
    "        st.error(\"‚ùå Unexpected value found in the file. Ensure proper format.\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"‚ùå An unexpected error occurred: {e}\")\n",
    "else:\n",
    "    st.info(\"üìÅ Please upload a CSV file to begin.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..F.\n",
      "======================================================================\n",
      "FAIL: test_invalid_csv (__main__.TestDQIDashboard)\n",
      "Test the script's error handling for invalid CSV.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_775/1243765372.py\", line 41, in test_invalid_csv\n",
      "    with self.assertRaises(pd.errors.ParserError):\n",
      "AssertionError: ParserError not raised\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.009s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "# test_dashboard.py\n",
    "\n",
    "import unittest\n",
    "import pandas as pd\n",
    "import io\n",
    "from dashboard import *  # Import the Streamlit app or functions directly\n",
    "\n",
    "class TestDQIDashboard(unittest.TestCase):\n",
    "\n",
    "    def test_dqi_computation(self):\n",
    "        \"\"\"Test if DQI is calculated correctly.\"\"\"\n",
    "        # Simulate a small DataFrame with missing values\n",
    "        df = pd.DataFrame({\n",
    "            'name': ['Alice', None],\n",
    "            'age': [25, 30]\n",
    "        })\n",
    "        total_cells = df.size\n",
    "        total_missing = df.isnull().sum().sum()\n",
    "        dqi = round((1 - (total_missing / total_cells)) * 100, 2)\n",
    "        self.assertEqual(dqi, 75.0)\n",
    "\n",
    "    def test_empty_file(self):\n",
    "        \"\"\"Test if the script handles empty CSV files.\"\"\"\n",
    "        # Simulate an empty file upload\n",
    "        df = pd.DataFrame()\n",
    "        self.assertEqual(df.shape[0], 0)\n",
    "\n",
    "    def test_missing_values(self):\n",
    "        \"\"\"Test if missing values are counted correctly.\"\"\"\n",
    "        df = pd.DataFrame({\n",
    "            'col1': [1, 2, None],\n",
    "            'col2': [None, 2, 3]\n",
    "        })\n",
    "        missing_values = df.isnull().sum()\n",
    "        self.assertEqual(missing_values['col1'], 1)\n",
    "        self.assertEqual(missing_values['col2'], 1)\n",
    "\n",
    "    def test_invalid_csv(self):\n",
    "        \"\"\"Test the script's error handling for invalid CSV.\"\"\"\n",
    "        invalid_csv = io.StringIO(\"col1,col2\\n1,2\\n3,4\")\n",
    "        with self.assertRaises(pd.errors.ParserError):\n",
    "            df = pd.read_csv(invalid_csv)  # Simulate malformed CSV\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=[''], exit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"id\": [1,2,3,4,5,6,7,8,9,10],\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\", \"Frank\", \"Grace\", \"Hank\", \"Ivy\", \"Jack\"],\n",
    "    \"age\": [25, None, 30, 27, None, 22, 29, 35, 28, 31],\n",
    "    \"email\": [\"alice@example.com\", \"bob[at]example.com\", None, \"david@example.com\", \"eve@example.com\",\n",
    "              \"frank@example.com\", \"grace@example.com\", \"hank@example.com\", \"ivy@example.com\", \"jack@example.com\"],\n",
    "    \"gender\": [\"F\", \"M\", \"M\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\"],\n",
    "    \"grade\": [\"A\", \"B\", \"C\", \"A\", \"B\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"data_quality_sample.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
