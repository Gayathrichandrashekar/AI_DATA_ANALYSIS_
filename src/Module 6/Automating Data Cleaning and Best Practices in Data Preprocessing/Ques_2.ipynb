{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Task: Complete Pipeline for a Dataset\n",
    "1. Objective: Build a complex pipeline with multiple transformations.\n",
    "2. Steps:\n",
    "    - Load a sample dataset.\n",
    "    - Define a transformation pipeline with both imputation and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Data (Imputed and Scaled):\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           0.000000          1.019004          -1.354309         -1.315444\n",
      "1          -1.152203         -0.131979          -1.354309         -1.315444\n",
      "2          -1.395201          0.328414          -1.411410         -1.315444\n",
      "3          -1.516700          0.098217          -1.297209         -1.315444\n",
      "4          -1.030704          1.249201          -1.354309         -1.315444\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# --- Load a Sample Dataset ---\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# Introduce missing values for demonstration\n",
    "df.iloc[0, 0] = np.nan  # Missing value in the first feature (Feature1)\n",
    "df.iloc[5, 2] = np.nan  # Missing value in the third feature (Feature3)\n",
    "\n",
    "# --- Define the Pipeline ---\n",
    "# Define a pipeline with imputation and scaling transformations\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values using the mean strategy\n",
    "    ('scaler', StandardScaler())  # Scale the numerical features\n",
    "])\n",
    "\n",
    "# --- Apply the Pipeline ---\n",
    "# Apply the pipeline to the dataset to perform both imputation and scaling\n",
    "processed_data = pipeline.fit_transform(df)\n",
    "\n",
    "# Convert the processed data back into a DataFrame\n",
    "processed_df = pd.DataFrame(processed_data, columns=df.columns)\n",
    "\n",
    "# Show the processed data\n",
    "print(\"Processed Data (Imputed and Scaled):\")\n",
    "print(processed_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data with Missing Values:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                NaN               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n",
      "\n",
      "Processed Data (Imputed and Scaled):\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           0.000000          1.019004          -1.354309         -1.315444\n",
      "1          -1.152203         -0.131979          -1.354309         -1.315444\n",
      "2          -1.395201          0.328414          -1.411410         -1.315444\n",
      "3          -1.516700          0.098217          -1.297209         -1.315444\n",
      "4          -1.030704          1.249201          -1.354309         -1.315444\n"
     ]
    }
   ],
   "source": [
    "# Task: Imputation Function\n",
    "\n",
    "# Task: Imputation Function\n",
    "\n",
    "\n",
    "\n",
    "def impute_data(df):\n",
    "    \"\"\"Impute missing values in the dataset using SimpleImputer with mean strategy.\"\"\"\n",
    "    imputer = SimpleImputer(strategy='mean')  # Impute missing values with the column mean\n",
    "    imputed_data = imputer.fit_transform(df)\n",
    "    return pd.DataFrame(imputed_data, columns=df.columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Scaling Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combined Transformation Function\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# --- Imputation Function ---\n",
    "def impute_data(df):\n",
    "    \"\"\"Impute missing values in the dataset using SimpleImputer with mean strategy.\"\"\"\n",
    "    imputer = SimpleImputer(strategy='mean')  # Impute missing values with the column mean\n",
    "    imputed_data = imputer.fit_transform(df)\n",
    "    return pd.DataFrame(imputed_data, columns=df.columns)\n",
    "\n",
    "# --- Scaling Function ---\n",
    "def scale_data(df):\n",
    "    \"\"\"Scale the numerical data using StandardScaler.\"\"\"\n",
    "    scaler = StandardScaler()  # Standardize features by removing the mean and scaling to unit variance\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "    return pd.DataFrame(scaled_data, columns=df.columns)\n",
    "\n",
    "# --- Combined Transformation Function ---\n",
    "def combined_transformation(df):\n",
    "    \"\"\"Apply both imputation and scaling to the dataset.\"\"\"\n",
    "    # Step 1: Impute missing values\n",
    "    df_imputed = impute_data(df)\n",
    "    \n",
    "    # Step 2: Scale the features\n",
    "    df_scaled = scale_data(df_imputed)\n",
    "    \n",
    "    return df_scaled\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# Introduce missing values for demonstration\n",
    "df.iloc[0, 0] = np.nan  # Missing value in the first feature (Feature1)\n",
    "df.iloc[5, 2] = np.nan  # Missing value in the third feature (Feature3)\n",
    "\n",
    "# Display original data with missing values\n",
    "print(\"Original Data with Missing Values:\")\n",
    "print(df.head())\n",
    "\n",
    "# Apply the combined transformation\n",
    "processed_df = combined_transformation(df)\n",
    "\n",
    "# Show the processed dataset after imputation and scaling\n",
    "print(\"\\nProcessed Data (Imputed and Scaled):\")\n",
    "print(processed_df.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Scaling Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combined Transformation Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
