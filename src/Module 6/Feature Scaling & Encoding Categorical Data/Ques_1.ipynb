{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: Feature Scaling Impact on Model\n",
      "\n",
      "Accuracy without scaling: 1.0000\n",
      "Accuracy with Min-Max scaling: 0.9111\n",
      "\n",
      "Question 2: Min-Max Scaling\n",
      "\n",
      "Min-Max Scaled Data:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           0.222222          0.625000           0.067797          0.041667\n",
      "1           0.166667          0.416667           0.067797          0.041667\n",
      "2           0.111111          0.500000           0.050847          0.041667\n",
      "3           0.083333          0.458333           0.084746          0.041667\n",
      "4           0.194444          0.666667           0.067797          0.041667\n",
      "\n",
      "Question 3: Standardization (Z-score Scaling)\n",
      "\n",
      "Standardized (Z-score) Data:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0          -0.900681          1.019004          -1.340227         -1.315444\n",
      "1          -1.143017         -0.131979          -1.340227         -1.315444\n",
      "2          -1.385353          0.328414          -1.397064         -1.315444\n",
      "3          -1.506521          0.098217          -1.283389         -1.315444\n",
      "4          -1.021849          1.249201          -1.340227         -1.315444\n",
      "\n",
      "Question 4: Robust Scaling\n",
      "\n",
      "Robust Scaled Data:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0          -0.538462               1.0          -0.842857         -0.733333\n",
      "1          -0.692308               0.0          -0.842857         -0.733333\n",
      "2          -0.846154               0.4          -0.871429         -0.733333\n",
      "3          -0.923077               0.2          -0.814286         -0.733333\n",
      "4          -0.615385               1.2          -0.842857         -0.733333\n"
     ]
    }
   ],
   "source": [
    "# Question 1: Feature Scaling\n",
    "# Task: Explain why feature scaling is essential and demonstrate the impact of unscaled features on a machine learning model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 2: Min-Max Scaling\n",
    "# Task: Implement Min-Max Scaling on the Iris dataset.\n",
    "\n",
    "\n",
    "\n",
    "# Question 3: Standardization (Z-score Scaling)\n",
    "# Task: Implement Standardization using Z-score scaling on the Iris dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 4: Robust Scaling\n",
    "# Task: Implement Robust Scaling to handle outliers in the Iris dataset.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "# Question 1: Feature Scaling\n",
    "def feature_scaling_impact():\n",
    "    # Load the Iris dataset\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "\n",
    "    # Split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Unscaled model\n",
    "    model_unscaled = LogisticRegression(max_iter=200)\n",
    "    model_unscaled.fit(X_train, y_train)\n",
    "    y_pred_unscaled = model_unscaled.predict(X_test)\n",
    "    accuracy_unscaled = accuracy_score(y_test, y_pred_unscaled)\n",
    "\n",
    "    # Min-Max Scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Scaled model\n",
    "    model_scaled = LogisticRegression(max_iter=200)\n",
    "    model_scaled.fit(X_train_scaled, y_train)\n",
    "    y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
    "    accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "\n",
    "    print(f\"Accuracy without scaling: {accuracy_unscaled:.4f}\")\n",
    "    print(f\"Accuracy with Min-Max scaling: {accuracy_scaled:.4f}\")\n",
    "\n",
    "# Question 2: Min-Max Scaling\n",
    "def min_max_scaling():\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "\n",
    "    # Min-Max Scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Displaying first 5 rows of the scaled dataset\n",
    "    scaled_df = pd.DataFrame(X_scaled, columns=iris.feature_names)\n",
    "    print(\"Min-Max Scaled Data:\")\n",
    "    print(scaled_df.head())\n",
    "\n",
    "# Question 3: Standardization (Z-score Scaling)\n",
    "def standardization():\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "\n",
    "    # Standardization using Z-score Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_standardized = scaler.fit_transform(X)\n",
    "\n",
    "    # Displaying first 5 rows of the standardized dataset\n",
    "    standardized_df = pd.DataFrame(X_standardized, columns=iris.feature_names)\n",
    "    print(\"Standardized (Z-score) Data:\")\n",
    "    print(standardized_df.head())\n",
    "\n",
    "# Question 4: Robust Scaling\n",
    "def robust_scaling():\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "\n",
    "    # Robust Scaling\n",
    "    scaler = RobustScaler()\n",
    "    X_robust_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Displaying first 5 rows of the robustly scaled dataset\n",
    "    robust_scaled_df = pd.DataFrame(X_robust_scaled, columns=iris.feature_names)\n",
    "    print(\"Robust Scaled Data:\")\n",
    "    print(robust_scaled_df.head())\n",
    "\n",
    "# Running all tasks\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Question 1: Feature Scaling Impact on Model\\n\")\n",
    "    feature_scaling_impact()\n",
    "    print(\"\\nQuestion 2: Min-Max Scaling\\n\")\n",
    "    min_max_scaling()\n",
    "    print(\"\\nQuestion 3: Standardization (Z-score Scaling)\\n\")\n",
    "    standardization()\n",
    "    print(\"\\nQuestion 4: Robust Scaling\\n\")\n",
    "    robust_scaling()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
