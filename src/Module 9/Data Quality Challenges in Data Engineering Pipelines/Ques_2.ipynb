{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Handling Schema Mismatches using Spark\n",
    "**Description**: Use Apache Spark to address schema mismatches by transforming data to match\n",
    "the expected schema.\n",
    "\n",
    "**Steps**:\n",
    "1. Create Spark session\n",
    "2. Load dataframe\n",
    "3. Define the expected schema\n",
    "4. Handle schema mismatches\n",
    "5. Show corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "# Step 1: Create Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Handle Schema Mismatches\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Step 2: Load DataFrame\n",
    "# Assume you have a CSV file 'data.csv' with potential schema mismatches\n",
    "# For this example, we're using a sample DataFrame instead\n",
    "data = [\n",
    "    ('John', 28, 'HR'),\n",
    "    ('Alice', '29', 'Finance'),\n",
    "    ('Bob', 31, None),\n",
    "    ('Eve', None, 'IT')\n",
    "]\n",
    "\n",
    "# Column names may not match the expected schema, so we define them\n",
    "columns = ['name', 'age', 'department']\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Show the original DataFrame with potential mismatched schema\n",
    "df.show()\n",
    "\n",
    "# Step 3: Define the expected schema\n",
    "expected_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"department\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Step 4: Handle Schema Mismatches\n",
    "# 4.1: Cast the 'age' column to Integer (if it's not already) and handle any missing values\n",
    "df = df.withColumn(\"age\", df[\"age\"].cast(IntegerType()))\n",
    "\n",
    "# 4.2: Handle missing department values by filling them with a default value (e.g., \"Unknown\")\n",
    "df = df.fillna({\"department\": \"Unknown\"})\n",
    "\n",
    "# 4.3: Renaming any columns that don't match the expected names (if necessary)\n",
    "# Example: Renaming 'name' column to 'full_name' (if needed)\n",
    "df = df.withColumnRenamed(\"name\", \"full_name\")\n",
    "\n",
    "# Step 5: Show Corrected Data\n",
    "df.show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Detect and Correct Incomplete Data in ETL\n",
    "**Description**: Use Python and Pandas to detect incomplete data in an ETL process and fill\n",
    "missing values with estimates.\n",
    "\n",
    "**Steps**:\n",
    "1. Detect incomplete data\n",
    "2. Fill missing values\n",
    "3. Report changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
