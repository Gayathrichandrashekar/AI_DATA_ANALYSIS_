{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data Profiling to Understand Data Quality\n",
    "**Description**: Use basic statistical methods to profile a dataset and identify potential quality issues.\n",
    "\n",
    "**Steps**:\n",
    "1. Load the dataset using pandas in Python.\n",
    "2. Understand the data by checking its basic statistics.\n",
    "3. Identify null values.\n",
    "4. Check unique values for categorical columns.\n",
    "5. Review outliers using box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Ques_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IsolationForest\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mQues_1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generate_synthetic_data, clean_data, validate_data, detect_anomalies, normalize_data\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTestDataQualityStrategies\u001b[39;00m(unittest\u001b[38;5;241m.\u001b[39mTestCase):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtest_generate_synthetic_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Ques_1'"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from Ques_1 import generate_synthetic_data, clean_data, validate_data, detect_anomalies, normalize_data\n",
    "\n",
    "\n",
    "class TestDataQualityStrategies(unittest.TestCase):\n",
    "\n",
    "    def test_generate_synthetic_data(self):\n",
    "        \"\"\"Test for generating synthetic data\"\"\"\n",
    "        df = generate_synthetic_data(n_samples=1000)\n",
    "        \n",
    "        # Check the shape of the generated DataFrame\n",
    "        self.assertEqual(df.shape, (1000, 4), \"DataFrame shape mismatch\")\n",
    "        \n",
    "        # Check the columns\n",
    "        self.assertTrue(all(col in df.columns for col in ['age', 'income', 'score', 'region']), \"Missing columns in the generated data\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        self.assertTrue(df.isnull().sum().sum() > 0, \"No missing values detected in the generated data\")\n",
    "\n",
    "    def test_clean_data(self):\n",
    "        \"\"\"Test for cleaning the data\"\"\"\n",
    "        df = generate_synthetic_data(n_samples=1000)\n",
    "        \n",
    "        # Clean the data\n",
    "        df_cleaned = clean_data(df)\n",
    "        \n",
    "        # Check that there are no missing values\n",
    "        self.assertEqual(df_cleaned.isnull().sum().sum(), 0, \"Missing values not handled correctly\")\n",
    "        \n",
    "        # Check for duplicate removal\n",
    "        self.assertEqual(df_cleaned.duplicated().sum(), 0, \"Duplicates not removed\")\n",
    "\n",
    "    def test_validate_data(self):\n",
    "        \"\"\"Test for data validation\"\"\"\n",
    "        df = generate_synthetic_data(n_samples=1000)\n",
    "        \n",
    "        # Validate the data\n",
    "        df_validated = validate_data(df)\n",
    "        \n",
    "        # Check if income is non-negative\n",
    "        self.assertTrue((df_validated['income'] >= 0).all(), \"Income contains negative values\")\n",
    "        \n",
    "        # Check if score is between 0 and 100\n",
    "        self.assertTrue((df_validated['score'] >= 0).all() and (df_validated['score'] <= 100).all(), \"Score contains values out of range\")\n",
    "\n",
    "    def test_detect_anomalies(self):\n",
    "        \"\"\"Test for anomaly detection\"\"\"\n",
    "        df = generate_synthetic_data(n_samples=1000)\n",
    "        \n",
    "        # Clean the data\n",
    "        df_cleaned = clean_data(df)\n",
    "        \n",
    "        # Detect anomalies\n",
    "        df_with_anomalies = detect_anomalies(df_cleaned)\n",
    "        \n",
    "        # Check that anomalies are marked correctly\n",
    "        self.assertIn('anomaly', df_with_anomalies.columns, \"Anomaly column missing\")\n",
    "        self.assertTrue(df_with_anomalies['anomaly'].value_counts().sum() == df_with_anomalies.shape[0], \"Anomaly detection failed\")\n",
    "\n",
    "    def test_normalize_data(self):\n",
    "        \"\"\"Test for data normalization\"\"\"\n",
    "        df = generate_synthetic_data(n_samples=1000)\n",
    "        \n",
    "        # Normalize the data\n",
    "        df_normalized = normalize_data(df)\n",
    "        \n",
    "        # Check if the mean of 'age', 'income', and 'score' is approximately 0 after normalization\n",
    "        self.assertAlmostEqual(df_normalized['age'].mean(), 0, delta=0.1, msg=\"Age normalization failed\")\n",
    "        self.assertAlmostEqual(df_normalized['income'].mean(), 0, delta=0.1, msg=\"Income normalization failed\")\n",
    "        self.assertAlmostEqual(df_normalized['score'].mean(), 0, delta=0.1, msg=\"Score normalization failed\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Implement Simple Data Validation\n",
    "**Description**: Write a Python script to validate the data types and constraints of each column in a dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Define constraints for each column.\n",
    "2. Validate each column based on its constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Detect Missing Data Patterns\n",
    "**Description**: Analyze and visualize missing data patterns in a dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Visualize missing data using a heatmap.\n",
    "2. Identify patterns in missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Integrate Automated Data Quality Checks\n",
    "**Description**: Integrate automated data quality checks using the Great Expectations library for a dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Install and initialize Great Expectations.\n",
    "2. Set up Great Expectations.\n",
    "3. Add further checks and validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
