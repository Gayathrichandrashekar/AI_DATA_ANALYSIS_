{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI & Machine Learning for Data Quality\n",
    "**Description**: AI and machine learning can automate and enhance data quality checks by learning patterns and identifying anomalies more effectively than static rules.\n",
    "\n",
    "**Task 1**: Training a model to predict and flag unusual trend patterns in sales data that\n",
    "deviate from historical norms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# Suppress warnings (UserWarnings)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Function to generate synthetic data\n",
    "def generate_synthetic_data(size=120):\n",
    "    \"\"\"Generate synthetic data with anomalies.\"\"\"\n",
    "    try:\n",
    "        # Generating random data\n",
    "        ages = np.random.randint(20, 60, size)\n",
    "        salaries = np.random.randint(30000, 120000, size)\n",
    "\n",
    "        # Adding anomalies\n",
    "        anomalies = np.array([50, 200])  # example anomalies\n",
    "        ages = np.concatenate((ages, anomalies))\n",
    "        salaries = np.concatenate((salaries, anomalies))\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame({'age': ages, 'salary': salaries})\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating synthetic data: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to detect anomalies using IsolationForest\n",
    "def detect_anomalies(df):\n",
    "    \"\"\"Detect anomalies using Isolation Forest.\"\"\"\n",
    "    try:\n",
    "        # Validate that the columns are numeric\n",
    "        if not np.issubdtype(df['age'].dtype, np.number) or not np.issubdtype(df['salary'].dtype, np.number):\n",
    "            raise ValueError(\"Both 'age' and 'salary' columns must be numeric.\")\n",
    "\n",
    "        # Initialize Isolation Forest\n",
    "        model = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)\n",
    "        \n",
    "        # Fit the model and predict anomalies\n",
    "        model.fit(df[['age', 'salary']])\n",
    "        df['anomaly_score'] = model.decision_function(df[['age', 'salary']])\n",
    "        df['is_anomaly'] = model.predict(df[['age', 'salary']])\n",
    "\n",
    "        # Map predictions to 1 (anomaly) and 0 (normal)\n",
    "        df['is_anomaly'] = df['is_anomaly'].map({1: 0, -1: 1})\n",
    "        return df\n",
    "\n",
    "    except ValueError as e:\n",
    "        logging.error(f\"Data validation error: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during anomaly detection: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to visualize the anomalies\n",
    "def visualize_anomalies(df):\n",
    "    \"\"\"Visualize anomalies in the dataset.\"\"\"\n",
    "    try:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(df['age'], df['salary'], c=df['is_anomaly'], cmap='coolwarm', edgecolors='k', s=100)\n",
    "        plt.xlabel('Age')\n",
    "        plt.ylabel('Salary')\n",
    "        plt.title('Anomaly Detection in Synthetic Data')\n",
    "        plt.colorbar(label='Anomaly Status (1: Anomaly, 0: Normal)')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during visualization: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to save results to a CSV file\n",
    "def save_results(df, filename=\"anomalies_detected.csv\"):\n",
    "    \"\"\"Save the results to a CSV file.\"\"\"\n",
    "    try:\n",
    "        df.to_csv(filename, index=False)\n",
    "        logging.info(f\"Results saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving results: {e}\")\n",
    "        raise\n",
    "\n",
    "# Main function to handle the entire pipeline\n",
    "def run_anomaly_detection_pipeline(data_size=120):\n",
    "    \"\"\"Run the full anomaly detection pipeline.\"\"\"\n",
    "    try:\n",
    "        # Generate data\n",
    "        df = generate_synthetic_data(data_size)\n",
    "\n",
    "        # Detect anomalies\n",
    "        df = detect_anomalies(df)\n",
    "\n",
    "        # Visualize anomalies\n",
    "        visualize_anomalies(df)\n",
    "\n",
    "        # Save results\n",
    "        save_results(df)\n",
    "\n",
    "        logging.info(\"Anomaly detection pipeline executed successfully.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Anomaly detection pipeline failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Gracefully exit the Python script or environment\n",
    "def graceful_exit():\n",
    "    \"\"\"Exit the environment gracefully.\"\"\"\n",
    "    print(\"Exiting the environment gracefully...\")\n",
    "    exit()\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        run_anomaly_detection_pipeline()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred in the pipeline: {e}\")\n",
    "\n",
    "    graceful_exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**: Using clustering algorithms to detect duplicate records where entries are not\n",
    "exactly identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3**: Implementing classification models to validate data based on learned\n",
    "characteristics from labeled datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code from here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
