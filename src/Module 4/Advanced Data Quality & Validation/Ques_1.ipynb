{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ The dataset file was not found at the path: /workspaces/AI_DATA_ANALYSIS_/src/Module 4/Advanced Data Quality & Validation/path_to_your_dataset.csv\n",
      "\n",
      "âœ… Checking for Missing Values:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'isnull'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# ğŸ“Œ Step 5: Check for Missing Values\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ… Checking for Missing Values:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m missing_values \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnull\u001b[49m()\u001b[38;5;241m.\u001b[39msum()  \u001b[38;5;66;03m# Count missing values for each column\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(missing_values)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# ğŸ“Œ Step 6: Check for Duplicates\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'isnull'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ğŸ“Œ Step 1: Define the file path for the dataset (Replace with actual path to your CSV file)\n",
    "file_path = \"path_to_your_dataset.csv\"  # Replace this with your dataset file path\n",
    "\n",
    "# ğŸ“Œ Step 2: Check if the file exists and load the dataset\n",
    "if os.path.exists(file_path):  # Check if the file exists at the specified location\n",
    "    try:\n",
    "        # ğŸ“Œ Step 3: Load the dataset using pandas\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"âœ… Dataset loaded successfully.\")\n",
    "        \n",
    "        # ğŸ“Œ Step 4: Basic Overview of the Data\n",
    "        print(\"\\nâœ… Basic Data Overview:\")\n",
    "        print(df.info())  # Get a summary of the dataset (types, non-null counts, etc.)\n",
    "        print(\"\\nFirst 5 rows of the dataset:\")\n",
    "        print(df.head())  # Display the first 5 rows of the dataset\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading dataset: {e}\")\n",
    "else:\n",
    "    print(f\"âŒ The dataset file was not found at the path: {os.path.abspath(file_path)}\")\n",
    "\n",
    "# ğŸ“Œ Step 5: Check for Missing Values\n",
    "print(\"\\nâœ… Checking for Missing Values:\")\n",
    "missing_values = df.isnull().sum()  # Count missing values for each column\n",
    "print(missing_values)\n",
    "\n",
    "# ğŸ“Œ Step 6: Check for Duplicates\n",
    "print(\"\\nâœ… Checking for Duplicates:\")\n",
    "duplicates = df.duplicated().sum()  # Count duplicate rows\n",
    "print(f\"Duplicate rows: {duplicates}\")\n",
    "\n",
    "# ğŸ“Œ Step 7: Descriptive Statistics for Numerical Columns\n",
    "print(\"\\nâœ… Descriptive Statistics for Numerical Columns:\")\n",
    "print(df.describe())  # Summary statistics for numerical columns\n",
    "\n",
    "# ğŸ“Œ Step 8: Check for Outliers (Using IQR - Interquartile Range)\n",
    "print(\"\\nâœ… Detecting Outliers using IQR:\")\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR)))\n",
    "print(\"Outliers detected in the dataset:\")\n",
    "print(outliers)\n",
    "\n",
    "# ğŸ“Œ Step 9: Data Type Validation (Check for unexpected data types)\n",
    "print(\"\\nâœ… Checking Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# ğŸ“Œ Step 10: Categorical Data Consistency (Optional)\n",
    "categorical_columns = ['CategoryColumn1', 'CategoryColumn2']  # Replace with actual categorical column names\n",
    "for column in categorical_columns:\n",
    "    print(f\"\\nâœ… Unique values in column {column}:\")\n",
    "    print(df[column].unique())\n",
    "\n",
    "# ğŸ“Œ Step 11: Schema Validation (Optional)\n",
    "numeric_columns = ['Age', 'Salary']  # Replace with actual numeric column names\n",
    "for column in numeric_columns:\n",
    "    if not pd.api.types.is_numeric_dtype(df[column]):\n",
    "        print(f\"âŒ Column {column} contains non-numeric data.\")\n",
    "    else:\n",
    "        print(f\"âœ… Column {column} contains numeric data.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
