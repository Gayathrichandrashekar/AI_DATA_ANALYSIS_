{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gfhfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Original DataFrame with Duplicates:\n",
      "\n",
      "    ID     Name  Age     City\n",
      "0  101    Alice   25       NY\n",
      "1  102      Bob   30       LA\n",
      "2  103  Charlie   35  Chicago\n",
      "3  104    David   40  Houston\n",
      "4  105      Eva   28       LA\n",
      "5  101    Alice   25       NY\n",
      "6  103  Charlie   35  Chicago\n",
      "\n",
      "ðŸ”¸ Duplicate Rows (full row matches):\n",
      "    ID     Name  Age     City\n",
      "0  101    Alice   25       NY\n",
      "2  103  Charlie   35  Chicago\n",
      "5  101    Alice   25       NY\n",
      "6  103  Charlie   35  Chicago\n",
      "\n",
      "ðŸ”¸ Number of Fully Duplicated Rows: 2\n",
      "\n",
      "âœ… After Removing Full Duplicates:\n",
      "    ID     Name  Age     City\n",
      "0  101    Alice   25       NY\n",
      "1  102      Bob   30       LA\n",
      "2  103  Charlie   35  Chicago\n",
      "3  104    David   40  Houston\n",
      "4  105      Eva   28       LA\n",
      "\n",
      "ðŸ”¸ Duplicates Based on 'ID':\n",
      "    ID     Name  Age     City\n",
      "0  101    Alice   25       NY\n",
      "2  103  Charlie   35  Chicago\n",
      "5  101    Alice   25       NY\n",
      "6  103  Charlie   35  Chicago\n",
      "\n",
      "âœ… Data After Dropping Redundant IDs (Keep First):\n",
      "    ID     Name  Age     City\n",
      "0  101    Alice   25       NY\n",
      "1  102      Bob   30       LA\n",
      "2  103  Charlie   35  Chicago\n",
      "3  104    David   40  Houston\n",
      "4  105      Eva   28       LA\n",
      "\n",
      "ðŸ”¸ DataFrame with 'is_duplicate' flag:\n",
      "    ID     Name  Age     City  is_duplicate\n",
      "0  101    Alice   25       NY          True\n",
      "1  102      Bob   30       LA         False\n",
      "2  103  Charlie   35  Chicago          True\n",
      "3  104    David   40  Houston         False\n",
      "4  105      Eva   28       LA         False\n",
      "5  101    Alice   25       NY          True\n",
      "6  103  Charlie   35  Chicago          True\n",
      "\n",
      "ðŸ’¾ Saved cleaned file as 'Q12_cleaned_deduplicated.csv'\n"
     ]
    }
   ],
   "source": [
    "# Ques_12.ipynb - Dealing with Duplicates & Redundancy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# === Step 1: Generate Sample Data ===\n",
    "def generate_data():\n",
    "    data = {\n",
    "        'ID': [101, 102, 103, 104, 105, 101, 103],\n",
    "        'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Alice', 'Charlie'],\n",
    "        'Age': [25, 30, 35, 40, 28, 25, 35],\n",
    "        'City': ['NY', 'LA', 'Chicago', 'Houston', 'LA', 'NY', 'Chicago']\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df = generate_data()\n",
    "print(\"ðŸ”¹ Original DataFrame with Duplicates:\\n\")\n",
    "print(df)\n",
    "\n",
    "# === Step 2: Find and Count Duplicates ===\n",
    "print(\"\\nðŸ”¸ Duplicate Rows (full row matches):\")\n",
    "print(df[df.duplicated(keep=False)])\n",
    "\n",
    "print(\"\\nðŸ”¸ Number of Fully Duplicated Rows:\", df.duplicated().sum())\n",
    "\n",
    "# === Step 3: Remove Full Row Duplicates ===\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "print(\"\\nâœ… After Removing Full Duplicates:\")\n",
    "print(df_no_duplicates)\n",
    "\n",
    "# === Step 4: Identify Partial Duplicates (e.g., by 'ID') ===\n",
    "print(\"\\nðŸ”¸ Duplicates Based on 'ID':\")\n",
    "print(df[df.duplicated(subset=['ID'], keep=False)])\n",
    "\n",
    "# === Step 5: Remove Redundancy by Keeping First Entry per ID ===\n",
    "df_unique_by_id = df.drop_duplicates(subset=['ID'], keep='first')\n",
    "print(\"\\nâœ… Data After Dropping Redundant IDs (Keep First):\")\n",
    "print(df_unique_by_id)\n",
    "\n",
    "# === Step 6: Optional â€” Flagging Duplicate Groups ===\n",
    "df['is_duplicate'] = df.duplicated(subset=['ID'], keep=False)\n",
    "print(\"\\nðŸ”¸ DataFrame with 'is_duplicate' flag:\")\n",
    "print(df)\n",
    "\n",
    "# === Step 7: Save cleaned data ===\n",
    "df_unique_by_id.to_csv(\"Q12_cleaned_deduplicated.csv\", index=False)\n",
    "print(\"\\nðŸ’¾ Saved cleaned file as 'Q12_cleaned_deduplicated.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task B: Deduplication Techniques\n",
    "\n",
    "# 10. Remove Complete Duplicates:\n",
    "# - Drop duplicate rows and keep only the first occurrence.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 11. Subset Deduplication:\n",
    "# - Remove duplicates based on a subset of columns.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 12. Keep Last Occurrence:\n",
    "# - Drop duplicates but keep the last occurrence in the dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
