{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fuzzywuzzy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DBSCAN\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfuzzywuzzy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fuzz\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfuzzywuzzy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m process\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Step 1: Data Loading\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load your dataset\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fuzzywuzzy'"
     ]
    }
   ],
   "source": [
    "# Question: Advanced Deduplication Using Machine Learning\n",
    "# Description: Implement ML-based deduplication based on feature similarity.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import DBSCAN\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Step 1: Data Loading\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"your_dataset.csv\")\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "# Handle missing values (example: fill with mean or mode)\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Convert categorical columns to numerical ones (using label encoding)\n",
    "label_encoder = LabelEncoder()\n",
    "df['category_column'] = label_encoder.fit_transform(df['category_column'])\n",
    "\n",
    "# Step 3: Feature Engineering (if you have text columns, you can create text similarity features)\n",
    "# Example: Calculate text similarity using fuzzywuzzy\n",
    "\n",
    "def calculate_text_similarity(text1, text2):\n",
    "    return fuzz.ratio(text1, text2) / 100.0  # Returns a similarity score between 0 and 1\n",
    "\n",
    "# Applying to each pair of text data in the dataframe (you can also apply pairwise comparison if needed)\n",
    "df['text_similarity'] = df['text_column'].apply(lambda x: calculate_text_similarity(x, x))\n",
    "\n",
    "# Step 4: Clustering to Detect Duplicates\n",
    "\n",
    "# Assuming you have features that represent the data, such as 'text_similarity', 'numerical_feature1', etc.\n",
    "X = df[['numerical_feature1', 'numerical_feature2', 'text_similarity']].values\n",
    "\n",
    "# Using DBSCAN for clustering similar rows\n",
    "db = DBSCAN(eps=0.5, min_samples=5, metric='euclidean')  # eps is the maximum distance between two samples for them to be considered as in the same neighborhood.\n",
    "df['cluster'] = db.fit_predict(X)\n",
    "\n",
    "# Step 5: Deduplication\n",
    "\n",
    "# In the DBSCAN clustering result, -1 means that the point is considered as noise (not part of any cluster)\n",
    "# We can drop duplicates by checking for similar rows within each cluster\n",
    "deduplicated_df = df[df['cluster'] != -1].drop_duplicates(subset=['text_column', 'numerical_feature1', 'numerical_feature2'])\n",
    "\n",
    "# Alternatively, use the similarity matrix to drop duplicates by comparing rows with a similarity threshold.\n",
    "# For example:\n",
    "# similarity_matrix = cosine_similarity(X)\n",
    "# threshold = 0.9\n",
    "# duplicate_pairs = np.where(similarity_matrix > threshold)\n",
    "\n",
    "# Step 6: Save the deduplicated dataset\n",
    "deduplicated_df.to_csv(\"deduplicated_dataset.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
